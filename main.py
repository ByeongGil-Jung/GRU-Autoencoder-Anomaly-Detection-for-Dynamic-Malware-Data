import argparse

import os
import pathlib
import sys

default_dir_path = str(pathlib.Path(os.getcwd()).parent.absolute())

sys.path.append(default_dir_path)

from dataset.dataset import *
from trainer.trainer import *
from model.model_v3 import *
from domain.base import Hyperparameters


def main(args):
    # Hparams
    dataset_hparams = Hyperparameters(
        concat_column_list=["Pid", "MethodName", "ProcessName"],
        vectorizer=HashingVectorizer(n_features=64),
        window_size=128
    )
    dataloader_hparams = Hyperparameters(
        batch_size=128,
        num_workers=1,
        pin_memory=True,
        shuffle=False
    )

    training_hparams = Hyperparameters(
        n_epochs=10,
        lr=1e-3,
        weight_decay=0,
        save_dir_path="/workspace/Project/Pattern_Recognition/model/results_v3",
        device="cuda"
    )

    validation_hparams = Hyperparameters(
        save_dir_path="/workspace/Project/Pattern_Recognition/model/results_v3",
        device="cuda"
    )

    test_hparams = Hyperparameters(
        save_dir_path="/workspace/Project/Pattern_Recognition/model/results_v3",
        device="cuda",
        type_lower_bound=470,
        type_upper_bound=1000,
        type_1_threshold=0.076,
        type_2_threshold=0.09
    )

    model_hparams = Hyperparameters(
        input_size=64,
        hidden_1_size=256,
        hidden_2_size=128,
        #     hidden_3_size=64
    )

    normal_data_list = FeatureGenerator.get_sample_dir_path_list(sample_name="clean_entire")
    abnormal_data_list = FeatureGenerator.get_sample_dir_path_list(sample_name="virus_entire")

    data_dict = FeatureGenerator.train_val_test_split(
        normal_data_list=normal_data_list,
        abnormal_data_list=abnormal_data_list,
        train_ratio=0.7,
        val_ratio=0.1,
        test_ratio=0.2,
        is_shuffle=True
    )
    print(data_dict.keys())

    train_dataset_controller = SampleSequenceDatasetController(
        sample_dir_path_list=data_dict["train_X"],
        y_list=data_dict["train_y"],
        dataset_hparams=dataset_hparams,
        dataloader_hparams=dataloader_hparams
    )

    val_dataset_controller = SampleSequenceDatasetController(
        sample_dir_path_list=data_dict["val_X"],
        y_list=data_dict["val_y"],
        dataset_hparams=dataset_hparams,
        dataloader_hparams=dataloader_hparams
    )

    test_dataset_controller = SampleSequenceDatasetController(
        sample_dir_path_list=data_dict["test_X"],
        y_list=data_dict["test_y"],
        dataset_hparams=dataset_hparams,
        dataloader_hparams=dataloader_hparams
    )

    model = Model(hparams=model_hparams)
    model.to(training_hparams.device)

    # # Load
    # model_file_path = os.path.join(train_hparams.save_dir_path, train_hparams.model_file_name)
    #
    # model.load_state_dict(torch.load(model_file_path, map_location="cpu"))
    # model.to(train_hparams.device)

    trainer = Trainer(
        model=model,
        train_dataset_controller=train_dataset_controller,
        val_dataset_controller=val_dataset_controller,
        test_dataset_controller=test_dataset_controller,
        optimizer=torch.optim.Adam(
            model.parameters(),
            lr=training_hparams.lr,
            weight_decay=training_hparams.weight_decay
        ),
        loss_function=torch.nn.MSELoss(),
        training_hparams=training_hparams,
        validation_hparams=validation_hparams,
        test_hparams=test_hparams,
    )

    # Training
    trainer.train()

    # Validation
    trainer.validation()

    # Test
    trainer.test()

    # Scoring
    val_score_dict = trainer.score(result_dir_path=os.path.join(validation_hparams.save_dir_path, "validation"))
    test_score_dict = trainer.score(result_dir_path=os.path.join(validation_hparams.save_dir_path, "test"))

    print("====================================")
    print("Validation Score")
    print(val_score_dict)

    print("====================================")
    print("Test Score")
    print(test_score_dict)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="GRU-Autoencoder Anomaly Detection, Byeonggil Jung]")
    args = parser.parse_args()

    logger.info(f"Selected parameters : {args}")

    main(args=args)
