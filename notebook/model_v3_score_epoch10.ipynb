{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Model v3 Test ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020572045 정병길"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 777\n",
      "[2021-06-21 11:00:28,349][INFO][properties.py:22] Complete to apply the random seed, RANDOM_SEED : 777\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "default_dir_path = str(pathlib.Path(os.getcwd()).parent.absolute())\n",
    "\n",
    "sys.path.append(default_dir_path)\n",
    "\n",
    "from properties import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import *\n",
    "from trainer.trainer import *\n",
    "from model.model_v3 import *\n",
    "from domain.metadata import Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fg = FeatureGenerator()\n",
    "normal_data_list = FeatureGenerator.get_sample_dir_path_list(sample_name=\"clean_entire\")\n",
    "abnormal_data_list = FeatureGenerator.get_sample_dir_path_list(sample_name=\"virus_entire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire Normal data size : 739\n",
      "Entire Abnormal data size : 1000\n",
      "===========================================\n",
      "Train Normal dataset size : 517\n",
      "Val Normal | Abnormal dataset size : 73 | 73\n",
      "Test Normal | Abnormal dataset size : 149 | 149\n",
      "\n",
      "dict_keys(['train_X', 'train_y', 'val_X', 'val_y', 'test_X', 'test_y'])\n"
     ]
    }
   ],
   "source": [
    "data_dict = FeatureGenerator.train_val_test_split(\n",
    "    normal_data_list=normal_data_list, \n",
    "    abnormal_data_list=abnormal_data_list, \n",
    "    train_ratio=0.7, \n",
    "    val_ratio=0.1, \n",
    "    test_ratio=0.2, \n",
    "    is_shuffle=True\n",
    ")\n",
    "print(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hparams = Hyperparameters(\n",
    "    concat_column_list=[\"Pid\", \"MethodName\", \"ProcessName\"],\n",
    "    vectorizer=HashingVectorizer(n_features=64),\n",
    "    window_size=128\n",
    ")\n",
    "dataloader_hparams = Hyperparameters(\n",
    "    batch_size=128,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "training_hparams = Hyperparameters(\n",
    "    n_epochs=50,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0,\n",
    "    save_dir_path=\"/workspace/Project/Pattern_Recognition/model/results_v3\",\n",
    "    device=\"cuda:1\"\n",
    ")\n",
    "\n",
    "validation_hparams = Hyperparameters(\\\n",
    "    save_dir_path=\"/workspace/Project/Pattern_Recognition/model/results_v3\",\n",
    "    device=\"cuda:1\"\n",
    ")\n",
    "\n",
    "\n",
    "test_hparams = Hyperparameters(\n",
    "    save_dir_path=\"/workspace/Project/Pattern_Recognition/model/results_v3\",\n",
    "    device=\"cuda:1\",\n",
    "    type_lower_bound=470,\n",
    "    type_upper_bound=1000,\n",
    "    type_1_threshold=0.076,\n",
    "    type_2_threshold=0.09\n",
    ")\n",
    "\n",
    "\n",
    "model_hparams = Hyperparameters(\n",
    "    input_size=64,\n",
    "    hidden_1_size=256,\n",
    "    hidden_2_size=128,\n",
    "#     hidden_3_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_controller = SampleSequenceDatasetController(\n",
    "    sample_dir_path_list=data_dict[\"train_X\"],\n",
    "    y_list=data_dict[\"train_y\"],\n",
    "    dataset_hparams=dataset_hparams,\n",
    "    dataloader_hparams=dataloader_hparams,\n",
    "    is_shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset_controller = SampleSequenceDatasetController(\n",
    "    sample_dir_path_list=data_dict[\"val_X\"],\n",
    "    y_list=data_dict[\"val_y\"],\n",
    "    dataset_hparams=dataset_hparams,\n",
    "    dataloader_hparams=dataloader_hparams,\n",
    "    is_shuffle=False\n",
    ")\n",
    "\n",
    "test_dataset_controller = SampleSequenceDatasetController(\n",
    "    sample_dir_path_list=data_dict[\"test_X\"],\n",
    "    y_list=data_dict[\"test_y\"],\n",
    "    dataset_hparams=dataset_hparams,\n",
    "    dataloader_hparams=dataloader_hparams,\n",
    "    is_shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = sample_sequence_dataset_controller.get_concat_dataset(sample_idx=0)\n",
    "# dataloader = sample_sequence_dataset_controller.get_concat_dataloader(sample_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hparams=model_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder_rnn): EncoderRNN(\n",
       "    (rnn_1): GRU(64, 256, batch_first=True)\n",
       "    (rnn_2): GRU(256, 128, batch_first=True)\n",
       "  )\n",
       "  (decoder_rnn): DecoderRNN(\n",
       "    (rnn_2): GRU(128, 256, batch_first=True)\n",
       "    (rnn_3): GRU(256, 64, batch_first=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(training_hparams.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer.trainer import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder_rnn): EncoderRNN(\n",
       "    (rnn_1): GRU(64, 256, batch_first=True)\n",
       "    (rnn_2): GRU(256, 128, batch_first=True)\n",
       "  )\n",
       "  (decoder_rnn): DecoderRNN(\n",
       "    (rnn_2): GRU(128, 256, batch_first=True)\n",
       "    (rnn_3): GRU(256, 64, batch_first=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_name = \"model_10.pkl\"\n",
    "\n",
    "model_file_path = os.path.join(training_hparams.save_dir_path, model_file_name)\n",
    "model_file_path\n",
    "\n",
    "os.path.isfile(model_file_path)\n",
    "\n",
    "with open(model_file_path, \"rb\") as f:\n",
    "    model_state_dict = pickle.load(f)\n",
    "\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(validation_hparams.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset_controller=train_dataset_controller,\n",
    "    val_dataset_controller=val_dataset_controller,\n",
    "    test_dataset_controller=test_dataset_controller,\n",
    "    optimizer=torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=training_hparams.lr,\n",
    "        weight_decay=training_hparams.weight_decay\n",
    "    ),\n",
    "    loss_function=torch.nn.MSELoss(),\n",
    "    training_hparams=training_hparams,\n",
    "    validation_hparams=validation_hparams,\n",
    "    test_hparams=test_hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result_dir_path = os.path.join(validation_hparams.save_dir_path, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_normal_short_loss_list = list()\n",
    "val_normal_short_target_list = list()\n",
    "\n",
    "val_normal_long_loss_list = list()\n",
    "val_normal_long_target_list = list()\n",
    "\n",
    "val_abnormal_short_loss_list = list()\n",
    "val_abnormal_short_target_list = list()\n",
    "\n",
    "val_abnormal_long_loss_list = list()\n",
    "val_abnormal_long_target_list = list()\n",
    "\n",
    "for sample_file_name in os.listdir(validation_result_dir_path):\n",
    "    val_sample_file_path = os.path.join(validation_result_dir_path, sample_file_name)\n",
    "    \n",
    "    with open(val_sample_file_path, \"rb\") as f:\n",
    "        sample_result_dict = pickle.load(f)\n",
    "        \n",
    "    target = sample_result_dict[\"target\"][0]\n",
    "    num_batch = sample_result_dict[\"num_batch\"]\n",
    "    \n",
    "    if 470 <= num_batch < 1000:\n",
    "        if target == 0:\n",
    "            val_normal_short_loss_list.append(sample_result_dict[\"current_sample_loss\"])\n",
    "            val_normal_short_target_list.append(target)\n",
    "        elif target == 1:\n",
    "            val_abnormal_short_loss_list.append(sample_result_dict[\"current_sample_loss\"])\n",
    "            val_abnormal_short_target_list.append(target)\n",
    "        else:\n",
    "            assert False, f\"Unmatched target, {target}\"\n",
    "    else:\n",
    "        if target == 0:\n",
    "            val_normal_long_loss_list.append(sample_result_dict[\"current_sample_loss\"])\n",
    "            val_normal_long_target_list.append(target)\n",
    "        elif target == 1:\n",
    "            val_abnormal_long_loss_list.append(sample_result_dict[\"current_sample_loss\"])\n",
    "            val_abnormal_long_target_list.append(target)\n",
    "        else:\n",
    "            assert False, f\"Unmatched target, {target}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07675562585918701 0.0\n",
      "0.08222942136764945 0.0\n",
      "0.07479517193973921 0.0\n",
      "0.07866124497858558 0.0\n",
      "0.08196230797005481 0.0\n",
      "0.074485182762146 0.0\n",
      "0.07463617607330282 0.0\n",
      "0.07967771568595917 0.0\n",
      "0.07482300897336695 0.0\n",
      "0.07461097644421266 0.0\n",
      "0.07456156960975976 0.0\n",
      "0.07469546533114202 0.0\n",
      "0.07970800346933132 0.0\n",
      "0.08106467094758282 0.0\n",
      "0.07952963996330183 0.0\n",
      "0.07457300447021069 0.0\n",
      "0.07538123732587629 0.0\n",
      "0.07464969248976558 0.0\n",
      "0.07490227102744774 0.0\n",
      "0.07768551842627237 0.0\n",
      "0.07465458499888579 0.0\n",
      "0.07669115018318681 0.0\n",
      "0.0745830717688996 0.0\n",
      "0.0745651601318672 0.0\n",
      "0.07614802691409486 0.0\n",
      "0.07470072178625228 0.0\n",
      "0.07682157501782456 0.0\n",
      "0.07456176764502817 0.0\n",
      "0.07472629345351865 0.0\n",
      "0.0746585186878758 0.0\n",
      "0.07710971342005433 0.0\n",
      "0.07459679073663561 0.0\n",
      "0.07504710344448372 0.0\n",
      "0.07465579262934625 0.0\n",
      "0.07461107239748041 0.0\n",
      "0.07831532999254429 0.0\n",
      "0.07441601297452383 0.0\n",
      "0.07465418310704568 0.0\n",
      "0.07688597077870463 0.0\n",
      "0.07471056146003445 0.0\n",
      "0.0747888471848768 0.0\n",
      "0.07465743265893994 0.0\n",
      "0.07905758598782722 0.0\n",
      "0.07469530908865968 0.0\n",
      "0.07461269854083041 0.0\n",
      "0.07473320871777445 0.0\n",
      "0.08023891842693363 0.0\n",
      "0.07519408513397038 0.0\n",
      "0.07457712177568289 0.0\n",
      "0.07484086487726514 0.0\n",
      "0.07869164581419132 0.0\n",
      "0.07461535483901578 0.0\n",
      "0.08248332480434328 0.0\n"
     ]
    }
   ],
   "source": [
    "for loss, target in zip(val_normal_short_loss_list, val_normal_short_target_list):\n",
    "    print(loss, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07160878068594191 0.0\n",
      "0.0821485480034813 0.0\n",
      "0.08001994713188132 0.0\n",
      "0.06572447264473749 0.0\n",
      "0.08183645734645054 0.0\n",
      "0.0804486758909711 0.0\n",
      "0.07626334582996923 0.0\n",
      "0.07877806595332942 0.0\n",
      "0.0799836907919842 0.0\n",
      "0.08304806682078734 0.0\n",
      "0.07567368434035451 0.0\n",
      "0.08937038919696001 0.0\n",
      "0.08552761645967773 0.0\n",
      "0.08319429880307044 0.0\n",
      "0.08917306615508717 0.0\n",
      "0.07780137033490785 0.0\n",
      "0.08064915714975522 0.0\n",
      "0.0692747371284629 0.0\n",
      "0.09664336623054912 0.0\n",
      "0.08118250524842895 0.0\n"
     ]
    }
   ],
   "source": [
    "for loss, target in zip(val_normal_long_loss_list, val_normal_long_target_list):\n",
    "    print(loss, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07634260054903722 1.0\n",
      "0.07659165407804881 1.0\n",
      "0.07741490090336964 1.0\n",
      "0.07659657250138519 1.0\n",
      "0.0777455392908786 1.0\n",
      "0.07825167333574423 1.0\n",
      "0.07664164897875014 1.0\n",
      "0.07634503501329092 1.0\n",
      "0.07635250605080714 1.0\n",
      "0.09007163273963288 1.0\n",
      "0.07662681686633732 1.0\n",
      "0.07647752313046005 1.0\n",
      "0.07648157880915223 1.0\n",
      "0.07632891296096161 1.0\n",
      "0.076942975888151 1.0\n",
      "0.07666113191296947 1.0\n",
      "0.07632227846053967 1.0\n",
      "0.07641243606451012 1.0\n",
      "0.07631356243754407 1.0\n",
      "0.07689035613118678 1.0\n",
      "0.0767515368874699 1.0\n",
      "0.07635147109716597 1.0\n",
      "0.07530632735519059 1.0\n",
      "0.0765871908269217 1.0\n",
      "0.07731685126754465 1.0\n",
      "0.07642817225132603 1.0\n",
      "0.07628924031502644 1.0\n",
      "0.07643956807580325 1.0\n",
      "0.0789167632568471 1.0\n",
      "0.0763591037846411 1.0\n",
      "0.07760424239020194 1.0\n",
      "0.08214980528882763 1.0\n",
      "0.08178456294741039 1.0\n",
      "0.07757488858356351 1.0\n",
      "0.07659211341524497 1.0\n",
      "0.07671775702460139 1.0\n",
      "0.07621750528671482 1.0\n",
      "0.07725256816262291 1.0\n",
      "0.07660103909233038 1.0\n",
      "0.07639544732607756 1.0\n",
      "0.07887504154939604 1.0\n",
      "0.0806974805145461 1.0\n",
      "0.07638544108097751 1.0\n",
      "0.07638403304008534 1.0\n",
      "0.07665687828671698 1.0\n",
      "0.07635359679159563 1.0\n",
      "0.07690256467299239 1.0\n",
      "0.07619361515638894 1.0\n",
      "0.07668289879527618 1.0\n",
      "0.07661507839665693 1.0\n",
      "0.07633649977851674 1.0\n",
      "0.07837844397732638 1.0\n",
      "0.07794642336666584 1.0\n",
      "0.07632182204569003 1.0\n",
      "0.07667069550530584 1.0\n",
      "0.07644600478729399 1.0\n",
      "0.07628723992248297 1.0\n",
      "0.08128172242110787 1.0\n",
      "0.0762074866797775 1.0\n",
      "0.07659534018809401 1.0\n",
      "0.07677616689761635 1.0\n",
      "0.07716263280465052 1.0\n",
      "0.07658757089640844 1.0\n",
      "0.07624933781505328 1.0\n",
      "0.0763130962036927 1.0\n",
      "0.076612136865917 1.0\n"
     ]
    }
   ],
   "source": [
    "for loss, target in zip(val_abnormal_short_loss_list, val_abnormal_short_target_list):\n",
    "    print(loss, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09356024580469043 1.0\n",
      "0.08946718405122342 1.0\n",
      "0.0801738391158884 1.0\n",
      "0.11106421791451394 1.0\n",
      "0.10240291112451323 1.0\n"
     ]
    }
   ],
   "source": [
    "for loss, target in zip(val_abnormal_long_loss_list, val_abnormal_long_target_list):\n",
    "    print(loss, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0626"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_normal_short_pred_target = list(map(lambda loss: 1 if loss >= 0.076 else 0, val_normal_short_loss_list))\n",
    "val_abnormal_short_pred_target = list(map(lambda loss: 1 if loss >= 0.076 else 0, val_abnormal_short_loss_list))\n",
    "\n",
    "val_normal_long_pred_target = list(map(lambda loss: 1 if loss >= 0.09 else 0, val_normal_long_loss_list))\n",
    "val_abnormal_long_pred_target = list(map(lambda loss: 1 if loss >= 0.09 else 0, val_abnormal_long_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_target = val_normal_short_pred_target + val_abnormal_short_pred_target + val_normal_long_pred_target + val_abnormal_long_pred_target\n",
    "val_true_target = val_normal_short_target_list + val_abnormal_short_target_list + val_normal_long_target_list + val_abnormal_long_target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        21\n",
      "           1       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.88        25\n",
      "   macro avg       0.77      0.83      0.80        25\n",
      "weighted avg       0.89      0.88      0.89        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y_true=val_normal_long_pred_target + val_abnormal_long_pred_target, y_pred=val_normal_long_target_list + val_abnormal_long_target_list)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.73      0.82        73\n",
      "         1.0       0.77      0.96      0.86        71\n",
      "\n",
      "    accuracy                           0.84       144\n",
      "   macro avg       0.86      0.84      0.84       144\n",
      "weighted avg       0.86      0.84      0.84       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y_true=val_true_target, y_pred=val_pred_target)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.73      0.82        73\n",
      "         1.0       0.77      0.96      0.86        71\n",
      "\n",
      "    accuracy                           0.84       144\n",
      "   macro avg       0.86      0.84      0.84       144\n",
      "weighted avg       0.86      0.84      0.84       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_dict = trainer.score(result_dir_path=os.path.join(validation_hparams.save_dir_path, \"validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.58      0.70       149\n",
      "         1.0       0.68      0.92      0.78       146\n",
      "\n",
      "    accuracy                           0.75       295\n",
      "   macro avg       0.78      0.75      0.74       295\n",
      "weighted avg       0.78      0.75      0.74       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_dict = trainer.score(result_dir_path=os.path.join(validation_hparams.save_dir_path, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
